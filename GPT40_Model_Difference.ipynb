{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of ChatGPT 4 Latest Models Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this small experiment is to use the same set of instructions and compare the answers provided by different ChatGPT 4.0 models.\n",
    "\n",
    "The answers are limited to the content of a set of documents, therefore, a RAG approach is used.\n",
    "\n",
    "Created by: Jhonnatan Torres <br>\n",
    "May 7th, 2024\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I stored my OpenAI key in a .env file, as a result, if you want to reproduce this notebook, you would need to install `pip install python-dotenv`, create a `.env` file in the same directory than the notebook and add your key to the `OPENAI_API_KEY` entry in the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models to be used in this small experiment are referenced in the official documentation of OpenAI, https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4, these are part of the \"4.0\" family and are considered as the \"flagship\" models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-4-turbo\", \"gpt-4-turbo-2024-04-09\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the set of instructions, simple RAG application, with some follow-up capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FIRST_MESSAGE = '''You will be asked a series of questions or issues which can be found between \n",
    "the <QUESTION> XML Tags.\n",
    "A collection of documents that must be used to provide an answer to 'QUESTION' can be found \n",
    "between the <SOURCES> XML Tags.\n",
    "\n",
    "Use your experience as an AI Assistant, troubleshoot and respond with an answer to \n",
    "each 'QUESTION' following these guidelines:\n",
    "\n",
    "- Limit your knowledge to 'SOURCES' and determine if its content can provide a full and honest answer to 'QUESTION', \n",
    "  if it does, then respond with a honest answer. \n",
    "- Limit your answer to the content of the 'SOURCES'.  \n",
    "- Don't include more information or your chain of thought in the answer.\n",
    "- If you are unsure about the answer, or 'QUESTION' is not clear, or it is an  open question, then feel free \n",
    "  to respond with a follow-up question for the student to get a better understanding of the 'QUESTION' and \n",
    "  keep the troubleshooting.\n",
    "- If the content in the 'SOURCES' cannot provide a complete and honest answer to 'QUESTION' \n",
    "  then respond with \"IDK\".'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the sources that should be used to provide an Answer (*mix of real and made up documents*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCES='''\n",
    "DOC1234: In python a lambda function can be created following this structure ```lambda x: x**2```.\n",
    "DOC1235: Collection from the numbutils can be really handy to get the value counts of items in a list in python.\n",
    "DOC1236: You can elevate a number to an `x` power by using the `**``character in python, \n",
    "for example ```x ** 2** is equal to `x to the power of 2`.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## First Use Case:\n",
    "The question entered by the student is not clear, therefore, the expected answer that should be provided by the chatbot is a follow-up question for the student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Round: 0 ###\n",
      "Model[gpt-4-turbo]:\n",
      "Could you please clarify what specific task you are trying to accomplish?\n",
      "Model[gpt-4-turbo-2024-04-09]:\n",
      "Could you please clarify what you are trying to do?\n",
      "### Round: 1 ###\n",
      "Model[gpt-4-turbo]:\n",
      "Could you please clarify what you are trying to do?\n",
      "Model[gpt-4-turbo-2024-04-09]:\n",
      "Could you please clarify what specific task you are trying to accomplish?\n",
      "### Round: 2 ###\n",
      "Model[gpt-4-turbo]:\n",
      "Could you please clarify what you are trying to do?\n",
      "Model[gpt-4-turbo-2024-04-09]:\n",
      "Can you please clarify what you are trying to do?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "for r in range(3):\n",
    "  print(f\"### Round: {r} ###\")\n",
    "  for m in models:\n",
    "    response = client.chat.completions.create(\n",
    "      model = m,\n",
    "      messages = [\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"You are a friendly AI Assistant helping to students who have a basic knowledge \\\n",
    "            about programming languages\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": USER_FIRST_MESSAGE\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": \"OK. Instructions Are Clear.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": f\"<QUESTION>How can I create a lambda function in Python?</QUESTION>\\n<SOURCES>\\{SOURCES}</SOURCES>\\nOutput:\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": \"To create a lambda function in Python, you can use the following structure: `lambda x: x**2.`\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": f\"<QUESTION>How can I do this?</QUESTION>\\n<SOURCES>\\n{SOURCES}\\n</SOURCES>\\nOutput:\"\n",
    "        }\n",
    "      ],\n",
    "      temperature=0.1,\n",
    "      max_tokens=50,\n",
    "      top_p=0.1,\n",
    "    )\n",
    "    print(f\"Model[{m}]:\")\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the official documentation of OpenAI (https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4) the `gpt-4-turbo` and `gpt-4-turbo-2024-04-09` are pointing to the same endpoint\n",
    "> gpt-4-turbo <br>\n",
    "> \"GPT-4 Turbo with Vision\n",
    "> The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling. Currently points to gpt-4-turbo-2024-04-09.\"\n",
    "\n",
    "> gpt-4-turbo-2024-04-09<br>\n",
    "> \"GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version.\"\n",
    "\n",
    "However, in this small test, we got a *similar* answer in 1 (Round #2) round out of 3. In the other 2 rounds (Round #1 and Round #2) the answers provided by the models were different. Based on the documentation, one, would assume the models are pointing to the same endpoint, hence, the answers should by the same or pretty similar.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Use Case:\n",
    "Providing an answer to the question entered by the student based on the sources only. (RAG Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Round: 0 ###\n",
      "Model[gpt-4-turbo]:\n",
      "IDK\n",
      "Model[gpt-4-turbo-2024-04-09]:\n",
      "Using the collection from the numbutils can be really handy to get the value counts of items in a list in Python.\n",
      "### Round: 1 ###\n",
      "Model[gpt-4-turbo]:\n",
      "You can use the collection from the numbutils to get the value counts of items in a list in Python.\n",
      "Model[gpt-4-turbo-2024-04-09]:\n",
      "Using the collection from the numbutils can be really handy to get the value counts of items in a list in Python.\n",
      "### Round: 2 ###\n",
      "Model[gpt-4-turbo]:\n",
      "You can use the collection from the numbutils to get the value counts of items in a list in Python.\n",
      "Model[gpt-4-turbo-2024-04-09]:\n",
      "IDK.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "for r in range(3):\n",
    "  print(f\"### Round: {r} ###\")\n",
    "  for m in models:\n",
    "    response = client.chat.completions.create(\n",
    "      model = m,\n",
    "      messages = [\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"You are a friendly AI Assistant helping to students who have a basic knowledge \\\n",
    "            about programming languages\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": USER_FIRST_MESSAGE\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": \"OK. Instructions Are Clear.\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": f\"<QUESTION>How can I create a lambda function in Python?</QUESTION>\\n<SOURCES>\\{SOURCES}</SOURCES>\\nOutput:\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"assistant\",\n",
    "          \"content\": \"To create a lambda function in Python, you can use the following structure: `lambda x: x**2.`\"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": f\"<QUESTION>How can I get the value counts of items in a list in python?</QUESTION>\\n<SOURCES>\\n{SOURCES}\\n</SOURCES>\\nOutput:\"\n",
    "        }\n",
    "      ],\n",
    "      temperature=0.1,\n",
    "      max_tokens=50,\n",
    "      top_p=0.1,\n",
    "    )\n",
    "    print(f\"Model[{m}]:\")\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was observed a similar behaviour than in the first use case, in just 1 round (Round #1) out of 3 the answers provided by both models were *similar*, in the other 2 rounds, either `gpt-4-turbo-2024-04-09` or `gpt-4-turbo` replied with \"IDK\" or the \"I don't know\" message. Again, based on the documentation, one would assume both models should provide similar answers if the 2 models are pointing to the same endpoint.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I know, it is not possible to draw conclusions with these simple experiments, however, my recommendation is to keep in mind these differences in the answers and the behaviour of the models when designing your RAG applications.\n",
    "\n",
    "    - Maybe, it can be a good idea to test with a small number of questions and compare the results provided by different models. (This can be like a \"Stage 0\" in the prompt engineering phase)\n",
    "\n",
    "- Note: I included the instructions in the first user message because I wanted to reduce the number of tokens used in each turn, this way, I am not sending the Question, Sources and Instructions in each user turn. *I know, it is not the common RAG approach*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
